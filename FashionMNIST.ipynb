{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.FashionMNIST('', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = torchvision.datasets.FashionMNIST('', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 6, 5, 4, 9, 6, 4, 6, 9, 5, 1, 1, 2, 1, 0, 2, 9, 1, 7, 9, 8, 2, 7, 2,\n",
      "        5, 8, 1, 3, 3, 3, 5, 5, 5, 0, 3, 8, 7, 0, 6, 1, 1, 9, 9, 0, 0, 9, 8, 2,\n",
      "        9, 7, 2, 0, 5, 2, 3, 7, 9, 8, 3, 9, 3, 4, 1, 0, 0, 2, 8, 1, 4, 0, 7, 7,\n",
      "        7, 0, 9, 5, 8, 9, 7, 6, 7, 6, 0, 7, 0, 9, 8, 5, 7, 9, 4, 6, 1, 4, 4, 7,\n",
      "        0, 8, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "train_set = torch.utils.data.DataLoader(dataset=train, batch_size=100, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(dataset=test, batch_size=100, shuffle=False)\n",
    "\n",
    "\n",
    "for data in train_set:\n",
    "    image,label = data\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2480951f100>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[0].squeeze(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=64)\n",
    "        self.out = nn.Linear(in_features=64, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2 , stride=2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = x.reshape(-1,12*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0611,  0.0749, -0.0880,  0.0255, -0.0056,  0.0808,  0.0014, -0.0525,\n",
       "         -0.0542,  0.0760]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.rand(1,1,28,28)\n",
    "preds = net(image)\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3532, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2763, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3417, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2324, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2529, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3633, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2962, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2881, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3621, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for batch in train_set:\n",
    "        images , labels = batch\n",
    "        \n",
    "        preds = net(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        losses.append(loss)\n",
    "    print(loss)\n",
    "   \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.89\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_set:\n",
    "        images, labels = batch\n",
    "        preds = net(images)\n",
    "        \n",
    "        for j, i in enumerate(preds):\n",
    "            if torch.argmax(i) == labels[j]:\n",
    "                correct += 1\n",
    "            total += 1    \n",
    "print('accuracy: ' ,(round(correct/total, 3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
